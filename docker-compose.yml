services:
  mlserver:
    build: 
      context: ./
      dockerfile: ./mlserver/Dockerfile
    image: mlserver
    expose:
      - 5001
    environment:
      - MODEL_NAME=triplet_model
    volumes:
      - ./mlruns:/mlruns

  webapp:
    build:
      context: ./
      dockerfile: ./webapp/Dockerfile
    image: webapp
    ports:
      - '5002:5000'
    environment:
      - MLSERVER_URL=http://mlserver:5001/predict
      - FLASK_APP=/webapp/app.py
    volumes:
      - ./data/drawings.geojson:/data/drawings.geojson # Optional