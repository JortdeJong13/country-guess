name: evaluate model

on:
  pull_request:
    paths:
      - "mlruns/models/**"
      - "data/**"
      - "tests/evaluation.py"

permissions:
  pull-requests: write
  contents: write

jobs:
  evaluate:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout PR branch
        uses: actions/checkout@v3
        with:
          ref: ${{ github.head_ref }}

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: |
          pip install -r mlserver/requirements.txt
          pip install -r webapp/requirements.txt

      - name: Run evaluation
        id: eval
        run: |
          report=$(make evaluate-model)
          echo "report<<EOF" >> $GITHUB_OUTPUT
          echo "$report" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Comment results on PR
        uses: marocchino/sticky-pull-request-comment@v2
        with:
          message: ${{ steps.eval.outputs.report }}

      - name: Create accuracy shield
        run: |
          top_1_acc=$(echo "${{ steps.eval.outputs.report }}" | grep "Top 1 Accuracy" | awk -F'|' '{print $3}' | tr -d ' %')
          top_1_acc=${top_1_acc:-0}
          cat <<EOF > data/accuracy-shield.json
          {
            "schemaVersion": 1,
            "label": "top-1-accuracy",
            "message": "$(printf "%.1f" $top_1_acc)%",
            "color": "blue"
          }
          EOF

      - name: Commit accuracy shield
        uses: stefanzweifel/git-auto-commit-action@v6
        with:
          file_pattern: data/accuracy-shield.json
          commit_message: Update accuracy shield [skip ci]
